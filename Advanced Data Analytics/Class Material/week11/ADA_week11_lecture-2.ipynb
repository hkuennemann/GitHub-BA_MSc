{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_qdBiDrxJos"
      },
      "source": [
        "# Graphframes example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN95L966xJou"
      },
      "source": [
        "Run the following cell to install the needed software."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOQ2TDRMxJov",
        "outputId": "877feae5-07b3-4c38-da1c-458aeb70c8d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "openjdk-11-jdk-headless is already the newest version (11.0.17+8-1ubuntu2~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 48.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=28f658b5f7624fc66c466bf7eef4393906ee06946d92f8ccfbac81b7f1c03428\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/59/f5/79a5bf931714dcd201b26025347785f087370a10a3329a899c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
            "--2022-11-23 13:57:20--  https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.2-s_2.12/graphframes-0.8.2-spark3.2-s_2.12.jar\n",
            "Resolving repos.spark-packages.org (repos.spark-packages.org)... 108.157.162.52, 108.157.162.51, 108.157.162.93, ...\n",
            "Connecting to repos.spark-packages.org (repos.spark-packages.org)|108.157.162.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 247880 (242K) [binary/octet-stream]\n",
            "Saving to: ‘graphframes-0.8.2-spark3.2-s_2.12.jar’\n",
            "\n",
            "graphframes-0.8.2-s 100%[===================>] 242.07K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-11-23 13:57:20 (4.18 MB/s) - ‘graphframes-0.8.2-spark3.2-s_2.12.jar’ saved [247880/247880]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Run this cell to install Spark on Colab\n",
        "import sys\n",
        "import os\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt-get install openjdk-11-jdk-headless\n",
        "    !pip install pyspark    \n",
        "    !wget https://repos.spark-packages.org/graphframes/graphframes/0.8.2-spark3.2-s_2.12/graphframes-0.8.2-spark3.2-s_2.12.jar\n",
        "    os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars graphframes-0.8.2-spark3.2-s_2.12.jar pyspark-shell'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TKsvVc8xJov"
      },
      "source": [
        "Now you are ready to run spark programs using GraphFrames."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Aa2U3mM5xJow"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import *\n",
        "\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"Group project\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark.sparkContext.setLogLevel(\"ERROR\")\n",
        "if IN_COLAB :\n",
        "    spark.sparkContext.addPyFile('graphframes-0.8.2-spark3.2-s_2.12.jar')\n",
        "else:\n",
        "    spark.sparkContext.addPyFile('/usr/local/spark/jars/graphframes-0.8.2-spark3.2-s_2.12.jar')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from graphframes import *\n",
        "\n",
        "sqlContext = SQLContext(spark.sparkContext)\n",
        "\n",
        "# Create a Vertex DataFrame with unique ID column \"id\"\n",
        "v = sqlContext.createDataFrame([\n",
        "  (\"a\", \"Alice\", 34),\n",
        "  (\"b\", \"Bob\", 36),\n",
        "  (\"c\", \"Charlie\", 30),\n",
        "], [\"id\", \"name\", \"age\"])\n",
        "# Create an Edge DataFrame with \"src\" and \"dst\" columns\n",
        "e = sqlContext.createDataFrame([\n",
        "  (\"a\", \"b\", \"friend\"),\n",
        "  (\"b\", \"c\", \"follow\"),\n",
        "  (\"c\", \"b\", \"follow\"),\n",
        "], [\"src\", \"dst\", \"relationship\"])\n",
        "# Create a GraphFrame\n",
        "g = GraphFrame(v, e)\n",
        "\n",
        "# Query: Get in-degree of each vertex.\n",
        "g.inDegrees.show()\n",
        "\n",
        "# Query: Count the number of \"follow\" connections in the graph.\n",
        "print(g.edges.filter(\"relationship = 'follow'\").count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB7y4mkXyK3u",
        "outputId": "74217901-489c-4e4f-959c-f437f80aac02"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/context.py:114: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py:149: UserWarning: DataFrame.sql_ctx is an internal property, and will be removed in future releases. Use DataFrame.sparkSession instead.\n",
            "  \"DataFrame.sql_ctx is an internal property, and will be removed \"\n",
            "/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py:127: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
            "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+--------+\n",
            "| id|inDegree|\n",
            "+---+--------+\n",
            "|  b|       2|\n",
            "|  c|       1|\n",
            "+---+--------+\n",
            "\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFGCQPSNxJow"
      },
      "outputs": [],
      "source": [
        "# Run PageRank algorithm, and show results.\n",
        "results = g.pageRank(resetProbability=0.01, maxIter=10)\n",
        "results.vertices.select(\"id\", \"pagerank\").show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}